---
title: Hadoop 权威指南笔记
date: 2022-07-08 11:20:05
tags:
- Hadoop
categories: 
- Note
---

# Hadoop 权威指南

# 第一章
基本上概述Hadoop的发展历史和历程，在此章节比较省略的阅读。  
譬如，Hadoop市场被指带多项目组成的生态系统，而不仅是HDFS和Mapreduce。  
1. Mapreduce正是一个批量查询处理器，能够在有效时间内针对整个数据集进行动态查询。  
所以它基本是一个批处理系统，更适合无用户等待查询的离线使用场景。  
2. Hbase是一个以HDFS做底层存储可供在线访问的分布式 Key-Value 数据库。  
3. YARN(Yet Another Resource Negotiator)是一个集群资源管理系统，允许分布式程序基于Hadoop集群数据而运行。
4. Hadoop生态圈组件不包含Redis

> 相较于其他系统的优势
<style>
.center 
{
  width: auto;
  display: table;
  margin-left: auto;
  margin-right: auto;
}
</style>
<p align="center"><font face="黑体" size=2.>表1 比较</font></p>

<div class="center">

| |传统关系型数据库|MapReduce|
|:-:|:-:|:-:|
|数据大小|GB|PB|
|数据存取|交互式和批处理|批处理|
|更新|多次读写|一次写入、多次读取|
|事务|ACID|无|
|结构|写时模式|读时模式|
|完整性|高|低|
|横向扩展|非线性的|线性的|

</div>

>另一种区别
- 结构化数据
- 半结构化数据
- 非结构化数据  

Hadoop和关系型数据库(RDBMS)另一个区别在于数据集的结构化程度，在以上三种数据中Hadoop对半结构化数据和非结构化数据的处理非常有效，因为处理数据是才对数据解释（读时模式），这种模式灵活又避免了像RDBMS数据加载阶段带来的高开销，因为在Hadoop看来仅是一个文件拷贝。  
MapReduce以及Hadoop中其他处理模型是可以随着数据规模线性伸缩，数据量原来2倍，即运行时间2倍但是可以通过集群规模扩展将速度提升，这是SQL查询不具备的特性。


> 数据本地化(data locality)特性就是Hadoop数据处理的核心，并因此有着良好的性能。 Hadoop是通过显式网络拓扑结构来保留网络带宽的。并且这种排列方式没有降低Hadoop对计算密集型数据的分析能力。

# 第二章
> Hadoop 并行处理优势

Mapreduce分Map和Reduce两个阶段，每阶段都以K-V作为输入和输出，类型可选。并且编写Map和Reduce函数。  
在该章节中示例展示普通的统计查询每年最高气温和利用Hadoop的统计查询每年最高气温。可以将几十分钟的统计时间化为3秒就可以得出的结果。

> 作业

作业是客户端需要执行的一个工作单元：包括输入数据、MapReduce程序和配置信息。

> 任务

Hadoop将作业分成若干个任务(task)来执行，包括map任务和reduce任务。  
任务运行在集群节点上并通过YARN调度。  
> 分片

将MP中的输入数据划分等长的小数据块，称为输入分片(input split)或“分片”。为每个分片构建一个map任务。
并行处理分片，意味着比处理一整个数据集的时间需求要少得多。

> 分片大小

分片大小最好趋向于HDFS一个块大小，即128MB，但是可以调整。

> 数据本地化优化（在map任务中）

Hadoop在存储输入数据的节点上运行map任务就可以获得最佳性能（因为无需使用网络带宽资源）。
通常有三种情况：
1. 本地数据（最快）
2. 本地机架，但不是在同数据块上执行map任务(中等)
3. 异地机架，会使用网络资源（最慢）

> reduce任务

- reduce任务数量有默认值可以更改，并不是由数据大小而定。
- 多个reduce任务就会让没过map任务针对输出进行分区，分区会用到高效partitioner通过哈希函数分区。

> shuffle

shuffle是在map任务之后和reduce任务之前的数据流，因为在多个reduce任务下，有多个map任务输入，***所以对mapreduce的时间调优，shuffle参数很重要***。

> combiner函数

combiner属于一种优化方案，简的来说就是避免map和reduce任务之间的数据传输（减少作业时间和减少占用集群可用资源）。

有些combiner函数可以直接用reduce函数作为combiner函数，例如求最大求最小等，在每个map任务分别求出局部最大最小再最后汇总给reduce求全局最大最小。**但是求平均等不能套回combiner**。

combiner虽然有reduce般的相似性但是还是不能取代reduce，因为有些情况需要reduce处理不同map间相同key记录。

# 第三章
> HDFS设计

特点
- 超大文件
- 流式数据访问
- 商用硬件

不适用场景
- 低时延的数据访问
- 大量小文件
- 多用户写入，任意修改文件

> HDFS架构

1. 基本组成

HDFS架构包含三个部分：NameNode，DataNode，Client。

NameNode：NameNode用于存储、生成文件系统的元数据。运行一个实例。

Secondary NameNode:会定期合并编辑日志和命名空间镜像。

DataNode：DataNode用于存储实际的数据，将自己管理的数据块上报给NameNode ，运行多个实例。

Client：支持业务访问HDFS，从NameNode ,DataNode获取数据返回给业务。多个实例，和业务一起运行。

2. HDFS写流程

业务应用调用HDFS Client提供的API，请求写入文件。

HDFS Client联系NameNode，NameNode在元数据中创建文件节点。

业务应用调用write API写入文件。

HDFS Client收到业务数据后，从NameNode获取到数据块编号、位置信息后，联系DataNode，并将需要写入数据的DataNode建立起流水线。完成后，客户端再通过自有协议写入数据到DataNode1，再由DataNode1复制到DataNode2, DataNode3。

写完的数据，将返回确认信息给HDFS Client。

所有数据确认完成后，业务调用HDFS Client关闭文件。

业务调用close, flush后HDFSClient联系NameNode，确认数据写完成，NameNode持久化元数据。

3. HDFS读流程

业务应用调用HDFS Client提供的API打开文件。

HDFS Client联系NameNode，获取到文件信息（数据块、DataNode位置信息）。

业务应用调用read API读取文件。

HDFS Client根据从NameNode获取到的信息，联系DataNode，获取相应的数据块。(Client采用就近原则读取数据)。

HDFS Client会与多个DataNode通讯获取数据块。

数据读取完成后，业务调用close关闭连接。

> HDFS关键特性
- ***联邦存储机制***
- 数据存储策略
- ***HA高可靠性***
- 多方式访问机制
- 空间回收机制
- NN/DN主从模式
- 统一的文件系统命名空间
- 数据副本机制
- 元数据持久化机制
- 健壮机制

1. 联邦存储机制

块池（block pool）:属于某一命名空间(NS)的一组文件块。联邦环境下，每个namenode维护一个命名空间卷（namespace volume），包括命名空间的元数据和在该空间下的文件的所有数据块的块池。

namenode之间是相互独立的，两两之间并不互相通信，一个失效也不会影响其他namenode。

datanode向集群中所有namenode注册，为集群中的所有块池存储数据。

NameSpace（NS）：命名空间。HDFS的命名空间包含目录、文件和块。可以理解为NameNode所属的逻辑目录。

2. HDFS的高可靠性（HA）

HDFS的高可靠性（HA）主要体现在利用zookeeper实现主备NameNode，以解决单点NameNode故障问题。

ZooKeeper主要用来存储HA下的状态文件，主备信息。ZK个数建议3个及以上且为奇数个。

NameNode主备模式，主提供服务，备同步主元数据并作为主的热备。

ZKFC(ZooKeeper Failover Controller)用于监控NameNode节点的主备状态。

JN(JournalNode)用于存储Active NameNode生成的Editlog。Standby NameNode加载JN上Editlog，同步元数据。

> Filesystem类

通过FsUrlStreamHadnlerFactory实例调用java.net.URL对象的setURLStreamHandlerFactory()方法或者直接用FileContext接口更简单。  
默认缓冲区大小4KB。  

> 一致模型  

为了性能牺牲了一些POSIX要求，创建文件立即可见但是写入文件按内容并不保证立即可见，即使数据流已经刷新并存储，超过一个块后第一个数据块对新的reader就可见
当前正在写入的块对其他reader不可见。    
但是使用hflush方法可以强行将所有缓存刷新到datanode。

> distcp

    distcp并行复制，通过集群中并运行的map完成，没有reduce

# 第四章

> YARN

YARN是Hadoop的集群资源管理系统，现在可以支持其他的分布式计算模式。  
YARN提供请求和使用集群资源的API。  

> YARN应用运行机制

客户端联系资源管理器，运行application master进程。  
资源管理器找到一个容器中启动application master的节点管理器。  
在MapReduce应用中，YARN向资源管理器请求更多容器用于运行一个分布式计算。

> YARN资源请求模型  
> 
请求多个容器时，可以指定每个容器的计算机资源数量。
处理HDFS数据块回申请容器存储数据块三个复本节点。  
YARN可以在运行中的认识一时刻提出资源申请。  

> YARN好处

- 多租户
- 可扩展性
- 可用性
- 利用率

> YARN调度

- FIFO调度（简单，不适合大型集群）
- 容量调度器（与FIFO相比大作业执行时间长，小作业提交就启动）
- 公平调度器（高集群利用率，小作业也能及时完成）

# 第五章
> 数据完整性

CRC-32检验和 检验数据完整性，HDFS使用的是变体CRC-32C。如果HDFS就按测到错误就会向NameNode报告并且读取这个HDFS副本复制到另外一个datanode。


> 压缩

压缩格式与待处理的文件大小、格式和使用的工具相关。
下面按照效率从高到低排序。
1. 容器文件格式（顺序文件）、Avro数据文件、ORCFiles（这些文件格式支持压缩和切分）搭配快速压缩工具如LZO，LZ4和Snappy。  
2. 支持切分的压缩格式，如bzip2（虽然慢），通过索引实现切分的压缩格式，例如LZO。
3. 文件切分成块（无论是否支持切分）
4. 未压缩文件

mapreduce中使用压缩将mapreduce.output.fileoutputformat.compress属性设为true
mapreduce.output.fileoutputformat.compress.condec 压缩方法

> 序列化

序列化是指将结构化对象转化为字节流以便传输，反序列化就是把字节流转回结构化对象。

序列化用于分布式数据处理：进程间通信和永久存储

紧凑、快速、可扩展、支持互操作

> Text类和Java String类差别

1. 索引  
Text类索引编码后字节序列中的位置实现，非字符串中的Unicode字符，也不是Java char的编码单元（如String).  
2. Unicode  
String长度是所含char编码单元个数，Text对象是UTF-8编码的字节数。
3. 迭代   
转换text对象然后利用缓冲区对text独享反复调用bytestocodepoint静态方法。
4. 可变性  
与String相比，Text是可变的，
5. 重新排序  
Text的操作API少，多数情况需要转换为String对象，调用toStrig()方法实现。  

> SequenceFile  
- SequenceFile类非常合适为二进制K-V对提供持久数据结构
- SequenceFile作为小文件容器，将小文件包装起来获得更高效率存储和处理。
-  数据块压缩指一次性压缩多条记录，该方法压缩效率更高，利用记录间的相似性进行压缩。

> MapFile
- MapFile是已经排过序的SequenceFile，有索引，可以按键查找。
- 索引自身也是SequenceFile，并且索引能够加载进内存，所以实现了主数据文件快速查找。  
> Avro数据文件  

- 它是更好的二进制文件格式。  
- 某些方面类似顺序文件，面向大规模数据处理（紧凑且可切分），但可移植跨越不同的编程语言使用（Writable对象只用Java代码：顺序文件以Java为中心）。
- 且Avro已经被Hadoop生态系统的各个组件广为支持，默认是对二进制格式的较好选择。

# 第六章
> 配置的API  

- Configuration类的实例(org.apache.hadoop.conf)代表配置属性及其取值。  
- 从XML读取属性值。  
- get()方法允许为XML中没有定义的属性指定默认值。  
- 多个XML文件会覆盖之前的属性，除非被标记为final。  
- 系统属性优先级高于XML中定义属性优先级。  

> 开发环境POM
- hadoop-client
- junit
- mrunit
- hadoop-minicluster




> 伪分布式\单机\集群环境切换
- fs.deafultFS:file\hdfs
- mapreduce.framework.name:local\yarn
- yarn.resourecemanager.address:localhost:8032

> Tool
- Tool的所有实现都需要实现configurable（因为Tool继承于Configurable），Configured子类通常是一种最简单的实现方式。

> 作业调优


|范围|最佳实践|
|:-|:-|
|mapper的数量|mapper如果运行时间短尽量减少mapper数量使其尽量在一分钟左右。|
|reducer的数量|检查reducer数目是否超过1个，reduce任务运行五分钟左右，且能产出一个数据块的数据。|
|combiner|能否充分利用combiner减少通过shuffle传输的数据量|
|中间值的压缩|对map输出进行压缩几乎总能使作业执行得更快|
|自定义序列|自定义的Writable对象或自定义的comparator，确保已实现RawComparator|
|调整shuffle|MapReduce的shuffle过程可以对一些内存管理的参数调整弥补性能的不足|

> JobControl

    线性链表直接简单顺序执行，更复杂的结构则使用JobControl类，它可以按照依赖顺序来执行作业。  

> Oozie

    Oozie是一个运行工作流系统，有相互依赖的作业组成该工作流，并且更容易处理失败工作流的重运行。  

# 第七章

> MapReduce 作业运行机制
- 客户端，提交mapreduce作业
- YARN资源管理器，负责协调集群上计算机资源配置
- YARN节点管理器，负责启动和监视集群中机器上的计算容器
- application master，负责协调运行mapreduce作业的任务。它和mapreduce任务在容器中运行，这些容器由资源管理器分配并由节点管理器进行管理。
- 分布式文件系统（HDFS），用来与其他实体间共享作业文件。

> 作业提交过程

1. 向资源管理器请求一个新应用ID，用于MapReduce作业ID
2. 检查作业的输出说明。例如，如果没有指定输出目录或输出目录已经存在，作业就不提交，错误抛回给MapReduce
3. 计算作业的输入分片。如果分片无法计算，例如输入路径不存在，作业就不提交，错误返回给MapReduce程序。
4. 将运行作业所需要的资源（包括作业JAR文件、配置文件按和计算所得的输入分片）复制到一个以作业ID命名的目录下的共享文件系统中。
5. 通过调用资源管理器的submitApplication()方法提交作业。

> Streaming

    Streaming任务使用标准输入和输出流与进程(任何语言)进行通信。

> 任务失败

- 任务失败的超时(mapreduce.task.timeout)设置为0将会关闭超市判定，从而有可能影响集群效率。默认该间隔为十分钟。  
- 超时后application master会进行重新调度执行但当失败(mapreduce.map/reduce.maxattempts)4次，将不会再重试。  
- 不触发作业失败下任务失败的最大百分比(mapreduce.map/reduce.failures.maxpercent)

> application master 运行失败

- mapreduce.am.mat-attempts默认值为2，即如果am失败两次将不会再尝试，作业失败。
- 同时更改上述属性值时需要在集群上的YARN同样设置(yarn.resourcemanager.amw.max-attempts)默认值2，否则将不会超过2这个限制  

> 节点管理器运行失败  

    发送心跳信息(yarn.resourcemanager.nm.liveness-monitor.expiry.interval-ms) 默认十分钟，节点管理器运行失败资源管理器就会通知将其从自己的节点池中移除以调度启用容器。

> 资源管理器运行失败

- 资源管理器运行失败是非常严重的问题，会导致作业和任务容器都无法启动并且所有作业都失败且不能被恢复。
- 为了HA(高可用性)，双机热备配置下运行一堆资源管理器是必要的，主资源管理器失败，那么备份资源管理器就能够接替。 
- 资源管理器切换由故障转移控制器(failover controller)处理。***是用ZooKeeper的leader选举机制（leader election）确保同一时刻只有一个主资源管理器。***

>## shuffle和排序  

> map端
- MP确保每个reducer的输入都是按键排序的。系统执行排序、将map输出作为输入传给reducer的过程成为shuffle。
- map任务有环形内存缓冲区用于存储任务输出，缓冲区大小（mapreduce.task.io.sort.mb）默认100MB,阈值(mapreduce.map.sort.spill.percent)默认0.8，即缓冲区达到80%阈值就会将内容spill（溢出）到磁盘。**溢出写过程将按轮询方式将缓冲区内容写到mapreduce.cluster.local.dir**属性在作业特定子目录下指定的目录中。
- combiner函数在排序后输出上运行，使得输出结果更紧凑，从而减少磁盘的数据和传递给reducer的数据。
- 任务工作完成前，**spill files被合并成一个已经分区且已经排序的删除文件(mapreduce.task.io.sort.factor)默认10，指一次合并多少流。**
- **(mapreduce.map.combiner.minspills)默认为存在3个溢出文件时，combiner就会在输出文件写到磁盘之前再次运行。**
- mapreduce.map.output.compress设置true启用输出压缩减少传给reducer数据量，节约磁盘空间。  mapreduce.map.output.compress.codec指定压缩方式


> reduce端

- reducer通过HTTP得到输出文件分区，用于文件分区的工作线程数量由任务的mapreduce.shuffle.max.threads属性控制，此设置针对的是每一个节点管理器，而不是针对每个map任务。默认值0将最大线程数设置为机器中处理器数量的2倍。
- map输出文件位于map任务的tasktracker的本地磁盘，tasktracker为分区文件运行reduce任务。因为map任务完成时间可能不同，所以reduce任务在map完成时就开始复制输出，(mapredeuc.reduce.shuffle.parallelcopies)默认值是5个线程。
- reducer用心跳机制线程定期询问application master从而得到map输出主机的位置，知道获得所有输出位置。
- 第一个reducer检索到map输出后需要等到am返回删除map输出命令才会删除，当然这是作业完成后执行的。
- map输出小时，会被复制到reduce任务的JVM内存(缓冲区大小由mapreduce.reduce.shuffle.input.buffer.percent默认值为0.7)。否则map输出被复制到磁盘，并且
内存缓冲区达到阈值大小(mapreduce.reduce.shuflle.merge.percent默认值0.66)或者达到map输出阈值(mapreduce.reduce.merge.inmem.threshold默认值1000)合并后溢出写到磁盘中。如果指定combiner，合并期间运行它以降低写入硬盘的数据量。
- 复制阶段完成后，进入(排序)合并阶段，合并map输出，维持其顺序排序(mapreduce.task.io.sort.factor默认值为10)。但是因子为10不代表每次合并10个文件，目的是尽量减少写到磁盘数据量，因为最后一趟总是直接合并到reduce。
> ## 配置调优

<p align="center"><font face="黑体" size=2.>表3 map端的调优属性</font></p>  

|属性名称|类型|默认值|说明|
|:-:|:-:|:-:|:-|
|mapreduce.task.io.sort.mb|int|100|排序map输出是所使用的内存缓冲区大小，MB为单位|
|mapreduce.map.sort.spill.percent|float|0.80|map输出内存缓冲和用来开始磁盘溢出写过程的记录边界索引，这两者使用比例的阈值|
|mapreduce.task.io.sort.factor|int|10|排序文件时，一次最多合并的流数。这个属性也在reduce中使用。将此值增加到100|
|mapreduce.map.combine.minspills|int|3|运行combiner所需的最少溢出文件数(如果已经指定combiner)|
|mapreduce.map.output.compress|Boolean|false|是否压缩map输出|
|mapreduce.map.output.compress.codec|Class name|org.apache.hadoop.io.compress.DefaultCodec|用于map输出的压缩编解码器|
|mapreduce.shuffle.max.threads|int|0|每个节点管理器的工作线程数，用于将map输出到reducer。这是集群范围的设置，不能由单个作业设置。0表示使用Netty默认值，即两倍于可用的处理器数量|

要尽量避免多次溢出写磁盘来获得最佳性能；通过估算map输出大小（估算方法：通过MapReduce计数器计算作业运行整个阶段溢出写磁盘的记录数，但是这个计数器包括map和reduce两端的溢出写）。

<p align="center"><font face="黑体" size=2.>表4 reduce端的调优属性</font></p>  

|属性名称|类型|默认值|说明|
|:-:|:-:|:-:|:-|
|mapreduce.reduce.shuffle.parallelcopies|int|5|用于把map输出复制到reducer的线程数|
|mapreduce.reduce.shuffle.maxfetchfailures|int|10|声明失败之前，reducer获取一个map输出所花最大时间|
|mapreduce.task.io.sort.factor|int|10|排序文件时一次最多合并的流的数量。这个属性也在map端使用|
|mapreduce.shuffle.inpute.buffer.percent|float|0.70|在shuffle的复制阶段，分配给map输出的缓冲区占堆空间的百分比|
|mapreduce.reduce.shuffle.merge.percent|float|0.66|map输出缓冲区(由mapred.job.shuffle.input.buffer.percent配置，默认是JVM的heap size的70%)的阈值使用比例，用于启动合并输出和磁盘一处写的过程|
|mapreduce.reduce.merge.inmem.threshold|int|1000|启动合并输出和磁盘溢出写过程的map输出的阈值数。0或更小的数意味着没有阈值限制，溢出写行为由mapreduce.reduce.shuffle.merge.percent单独控制|
|mapreduce.reduce.input.buffer.percent|float|0.0|在reduce过程中，内存中保存map输出的空间占整个堆空间的比例。reduce阶段开始时，内存中的map输出大小不能大于这个值。默认情况下，在reduce任务开始之前，所以map输出都合并到磁盘上为reducer提供尽可能多的内存。然而，如果reducer需要内存少可以增加此值减少访问磁盘次数|

***reduce端***，***中间数据***全部驻留在内存时，就能获得最佳性能。但是需要所有内存一般都预留给***reduce函数***但是如果reduce函数所需内存不大可以设置mapreduce.reduce.input.buffer.percent为更大的值(1.0)，mapreduce.reduce.merge.inmem.threshold更小的值(0)。

> 推测执行

推测执行是一种优化措施，并不保障作业的可靠运行，所以当一些软件缺陷导致的运行慢应当修复而不是通过推测执行解决。
默认情况下，推测执行是启用的，可以基于集群或基于每个作业，单独为map任务和reduce任务启用或禁用该功能。
<p align="center"><font face="黑体" size=2.>表5 推测执行的属性</font></p>  

|属性名称|类型|默认值|说明|
|:-:|:-:|:-:|:-|
|mapreduce.map.speculative|boolean|true|如果任务运行变慢，该属性觉得是否启动map任务的另外一个实例|
|mapreduce.reduce.speculative|boolean|true|如果任务运行变慢，该属性觉得是否启动reduce任务的另外一个实例|
|Yarn.app.mapreduce.am.job.speculator.class|Class|Org.apache.hadoop.mapreduce.v2.app.speculate.DefaultSpeculator|Speculator类实现推测执行策略(只针对MP2)|
|Yarn.app.mapreduce.am.job.estimator.class|Class|Org.apache.hadoop.mapreduce.v2.app.speculate.LegacyTaskRuntimeEstimator|Speculator实例使用的TaskRuntimeEstimator的实现，提供任务运行时间的估计值(只针对MP2)|

> OutputCommitters

    commitJob()方法会在作业成功同输出目录下创建一个名为_SUCCESS的隐藏标志文件。

# 第八章
> MapReduce类型

    map 输入的K-V不同于输出K-V，但是reduce的输入K-V与map输出K-V必须相同，reduce输出K-V可以不同于输入K-V。

partition函数对中间结果的K-V对进行处理，并且返回一个分区索引(partition index)。实际上，分区由键单独决定(值被忽略)。

> 默认Streaming作业

- 非Java的mapper，默认文本模式(-io text),那么Streaming不会把键传给mapper，只传递值。当为其他输入类型时，将stream.map.input.ignoreKey设置为true达到相同效果。
- 默认为Tab制表符(stream.map.input.field.separator)分割字段,键可以选择字段的前n个组成(stream.num.map.output.key.fields默认值为1)例如输出“a,b,c”(分隔符为逗号)，n设为2，则键“a,b”，值“c”

<p align="center"><font face="黑体" size=2.>表6 Streaming的分隔符属性</font></p>  

|属性名称|类型|默认值|说明|
|:-:|:-:|:-:|:-|
|stream.map/reduce.input.field.separator|String|\t|此分隔符用于将输入K-V字符串作为字节流传递到流map/reduce|
|stream.mao/reduce.output.field.separator|String|\t|此分隔符用于将流map/reduce处理的输出分割成map/reduce最终输出需要的K-V字符串|
|stream.num.map/reduce.output.key.fields|int|1|由stream.mao/reduce.output.field.separator分隔的字段数，这些字段作为map/reduce的输出键|

> 输入分片
- 输入分片就是由单个map操作来处理的输入块，每一个map操作只处理一个输入分片。
- 输入分片和记录都是逻辑概念。
- 输入分片在Java中表示为InputSplit接口，InputSplit指向的数据引用而不包含数据本身。存储位置供map任务放在附近，分片大小用来排序以便优先处理最大的分片，减少运行时间。  
- getSplits()计算分片，然后将发送到application master，application master调度map到这些分片数据的存储位置。map任务把输入分片传给InputFormat的createRecordReader()方法获得这个分片RecordReader，RecordReader时记录上的迭代器，用来生成记录的K-V再传递给map。


> FileInputFormat 类的输入路径

addInputPath()和addInputPaths()方法可以将一个或多个路径加入路径列表。setInputPaths()方法一次设定完整的路径列表(会替换在前面调用在Job上所设置的所有路径)

<p align="center"><font face="黑体" size=2.>表7 输入路径和过滤器属性</font></p>  

|属性名称|类型|默认值|说明|
|:-:|:-:|:-:|:-|
|mapreduce.input.fieldinputformat.inputdir|逗号分隔的路径|无|作业的输入文件。包含逗号的路径中的逗号由“\”符号转义。例如glob{a,b}变成glob{a\,b}|
|mapreduce.input.pathFilter.class|PathFilter类名|无|此分隔符用于将流map/reduce处理的输出分割成map/reduce最终输出需要的K-V字符串|

> FileInputFormat类的输入分片


由于FIP只分隔超过HDFS块大小的文件。而分片通常是与HDFS块大小一样，然而可以通过设置不同属性改变。

<p align="center"><font face="黑体" size=2.>表8 控制分片大小</font></p>  

|属性名称|类型|默认值|说明|
|:-:|:-:|:-:|:-|
|mapreduce.input.fieldinputformat.split.minsize|int|1|一个文件分片最小的有效字节数|
|mapreduce.input.fieldinputformat.split.maxsize|long|Long.MAX_VALUE,9223372036854775807=2^63-1|一个文件分片中最大的有效字节数|
|dfs.blocksize|long|128MB=134217728|HDFS中块的大小|

- 最小分片大小是1个字节，但是某些格式可以更小。
顺序文件每次插入一个同步入口，最小分片大小必须包括有个同步点以便reader重新同步。
- 可以强制分片比文件块大，但是如果数据存储在HDFS上，只会增加对map任务数而不是本地文件块数。  


     ***分片大小计算公式：max(minimumSize,min(maximumSize,blockSize))***


> CombineFileInputFormat

它可以把多个小文件打包到一个分片中以便mapper可以处理更多，决定哪些块放入同一个分片时，CFIF会考虑到节点和机架的insulting，所以在典型MapReduce作业中处理输入的速度并不会下降。

亦或者使用顺序文件将小文件合并成一个或多个大文件，将文件名作为键(或不需要键用NullWritable等常量代替)。

> 避免切分

1. 增加足校分片大小设置成大于要处理的最大文件大小。
2. 重写isSplitable()方法把返回值设置为false。

> mapper中的文件信息

<p align="center"><font face="黑体" size=2.>表9 文件输入分片的属性</font></p>  

|FileSplit方法|属性名称|类型|说明|
|:-:|:-:|:-:|:-|
|getPath()|mapreduce.map.input.file|Path/String|正在处理输入文件路径|
|getSTart()|mapreduce.map.input.start|long|分片开始处的自节偏移量|
|getLength() |mapreduce.map.input.length|long|分片的长度|

> 二进制输入
1. SequenceFile的顺序文件格式存储二进制的K-V序列，可分割，有同步。
2. SequenceFilesAS**将看作的对象不同。

> 多个输入

1. 虽然一个mp作业输入可能包含多个输入文件(glob、过滤器和路径组成)，但所有文件都有同一个InputFormat和同一个Mapper来解释，但是目前随时间演变数据格式会不同，即便格式相同表示也不同。所以需要MultipleInputs类来处理，MultipleInputs.addInputPath()为每条输入路径指定InputFormat和Mapper.
2. MultipleInputs.addInputPath()有另外一种重载无mapper参数，提供给多种输入格式一个mapper的情况，mapper通过Job的setMapperClass()设定。

> 文本输出

默认输出格式是TextOutputFormat，把每条记录写为文本行形式。

> 二进制输出

- SequenceFileOutputFormat输出写为一个顺序文件，如果后续输出需要MapReduce作为后续，这是一个好的输出格式。  
- SequenceFileAsBinaryInputFormat它以原始的二进制格式把K-V写到一个顺序文件容器中


> 多个输出

1. HashPartitioner决定分区数是更好的选择，可用的集群资源越多，作业完成越快。
2. 也就是说reducer需要写多个文件这就需要MultipleOutput类
3. MultipleOutput类可以为输出文件指定名字且显示块标识避免map输出和reduce输出文件冲突，也可以创建任意深度的子目录。

> 延迟输出

- 当程序需要输出文件有内容时才真正创建文件，那么LazyOutputFormat保证指定分区第一条记录输出时才真正创建文件。
- 作为参数调用setOutputFormatClass()或Streaming 支持-LazyOutput选项来启用LazyOutputFormat功能

> 数据库输入和输出
1. DBInputFormat支持JDBC从RDBMS中读取数据，但是它没有任何贡献能力，数据库中云太多mapper读数据可能会使数据库崩溃。所以最好加载小数据集，需要与HDFS的大数据集连接还是用MultipleInputs比较好，与之对应输出格式是DBOutputFormat。
2. RDBMS和HDFS之前转移数据可以用Sqoop。


# 第九章 MapReduce的特性

> 任务计数器

<p align="center"><font face="黑体" size=2.>表10 内置MapReduce任务计数器</font></p>  

|计数器名称| 说明|
|:-:|:-|
|map输入的记录数(MAP_INPUT_RECORDS)|作业中所有map已处理的输入记录数，每次RecordReader读到一条记录并将其传给map的map函数时，该计数器的值增加|
|分片(split)的原始字节数(SPLIT_RAW_BYTES))|由于map读取的输入-分片对象的字节数，这些对象描述分片元数据（带有文件位移和长度），而不是分片的数据本身|
|map输出的记录数(MAP_OUTPUT_RECORDS)|作业所有map产生的map输出记录数，每次map的OutputCollector调用collect()方法时，该计数器增加|
|map输出的字节数(MAP_OUTPUT_BYTES)|作业中所有map产生的未经压缩的输出数据的字节数。每次某一个map的OutCollector调用collect()方法时，该计数器的值增加|
|map输出的物化字节数(COMBINE_INPUT_RECORDS)|map输出后确实写道磁盘上的字节数；若map输出压缩功能被启用，则会在计数器值上反映出来。
|combine输入的记录数(COMBINE_INPUT_RECORDS)|combiner衣橱里的输入记录数。combiner的迭代器每次读一个值，该计数器的值增加。|
|combine输出的记录数(COMBINE_OUTPUT_RECORDS))|作业中所有combiner易产生的输出记录数。每当一个combiner的OutputCollector调用collect()方法时，该计数器的值增加。|
|reduce输入的组(REDUCE_INPUT_GROUPS)|作业中reducer已经处理不同的码分组的个数。每当某一个reducer的reduce()已经被调用时，该计数器的值增加|
|reduce输入的记录数(REDUCE_INPUT_RECORDS)|作业中所有reducer已经处理的输入记录个数。每当某个reducer的迭代器读一个值时，该计数器值增加。如果所有reducer处理完所有输入，则该值与“map输出的记录”相同|
|reduce经过shuffle的字节数(REDUCE_SHUFFLE_BYTES)|由shuffle复制到reducer的map输出的字节数|
|溢出的记录数(SPILLED_RECORDS)|作业中所有map和reduce任务溢出到磁盘的记录数|
|CPU毫秒(CPU_MILLISECONDS)|一个任务的总CPU时间，ms为单位，/proc/cpuinfo获取|
|物理内存字节数(PHYSICAL_MEMORY_BYTES)|一个任务所用的物理内存，B为单位，由/proc/meminfo|
|虚拟内存字节数(VIRTUAL_MEMORY_BYTES)|一个任务所用虚拟内存的字节数，/proc/meminfo获取|
|有效的堆字节数(COMMITTED_HEAP_BYTES)|在JVM中的总有效内存量(以字节为单位)，可由Runtime.getRuntime().totalMemory()获取|
|GC运行时间毫秒数(GC_TIME_MILLIS)|在任务执行过程中，垃圾收集器(garbage collection)花费的时间(以毫秒为单位)，可由GarbageCollector MXBean.getCollectionTime()获取|
|由shuffle传输的map字输出数(SHUFFLED_MAPS)||
|失败的shuffle数(FAILED_SHUFFLE)|shuffle过程中，发生map输出拷贝错误的次数|
|被合并的map输出数(MERGED_MAP_OUTPUTS)|shuffle过程中，在reduce端合并的map输出文件数|

# 第十章

> Hadoop配置文件

- hadoop-env.sh
- core-site.xml
- mapred-site.xml
- hdfs-site.xml
- mapred-env.sh
- yarn-env.sh
- yarn-site.xml
- slaves
- hadoop-metrics2.properties
- log4j.properties
- hadoop-policy.xml

> 环境设置

hadoop-env.sh文件，在MapReduce和YARN都有类似的配置，分别mapred-env.sh和yarn-env.sh会覆盖hadoop-env.sh的值。

hadoop-env.sh文件中设置JAVA_HOME项

Yarn本地存储会使用与datanode数据块存储相同的磁盘和分区(但是不同的目录)，datanode数据块存储目录由dfs.datanode.data.dir属性项指定。

yarn.resourecemaneger.hostname设定为主机名或IP地址，yarn.resourcemanager.bind-host设定为0.0.0.0,可以确定资源管理器能够与机器上的所有地址绑定，且同时能为节点管理器和客户端提供可解析的地址。

默认4KB的缓冲区辅助I/O操作，目前128KB更常用，增大缓冲区容量会显著提高性能。

HDFS块大小是128MB，但是许多集群设置为256MB降低namenode的内存压力，通过hdfs-site.xml的dfs.blocksize属性设置块大小。

短回路本地读，当从HDFS读取文件时，客户端联系datanode，然后数据通过TCP连接发送给客户端。如果正在读取的数据块和客户端在同一节点上，那么客户端绕过网络从磁盘上直接读取数据效率会更高。dfs.client.read.shortcircuit设置为true即可开启短回路本地读。

# 第十一章

> secondary namenode 创建检查点(条件:每一小时或事物达到100万个)
1. 请求主namenode停止edist logs，主namenode更新存储目录中的seen_txid
2. 获取fsimage和edits文件
3. secondary namenode 载入fsimage进内存，执行edits文件十五，创建合并的fsimage
4. 将新fsimage发回主namenode
5. 主namenode重新命名临时fsimage










问题：
1. Hadoop环境是搭建在Ubuntu还是Centos?虽然本科教学中使用的是Ubuntu但是感觉企业都是更倾向于Centos。
2. 公司项目中流数据处理通常是用什么呢？比如Hadoop、flink
3. 溢出的记录数(SPILLED_RECORDS)，作业中所有map和reduce任务溢出到磁盘的记录数。可以单独记录吗？
4. 第十章之后的真正分布式集群都是比较少真正接触的。
5. Hadoop环形缓冲区的FIFO
6. 一个MapReduce作业通常会把输入的数据集切分为若干独立的数据块，由map任务以完全串行的方式处理它们
   不是并行嘛？
7. 整个MapReduce框架负责任务的调度和监控，以及重新执行已经失败的任务
   这个是YARN负责调度吧？在2.x的话